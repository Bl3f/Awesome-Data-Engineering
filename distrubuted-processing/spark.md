# Spark

## Tutorial

[First Steps With PySpark and Big Data Processing](https://realpython.com/pyspark-intro/) - by Real Python  
  -  _docker로 간단한 예제 실행_

[A Neanderthal’s Guide to Apache Spark in Python](https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427)  
  -  _Spark 기초 용어에 대한 친절한 설명 + SparkSQL 간단한 예제_

[Apache Spark\(PySpark\) in Google Collaboratory](https://medium.com/@sushantgautam_930/apache-spark-in-google-collaboratory-in-3-steps-e0acbba654e6)  
  -  _Google Colaboratory에 spark를 설치 후 사용하는 방법 \( 디스크 용량을 위해 GPU RUNTIME에서 실행 권장 \)_

\_\_[Learning Apache Spark with Python](https://runawayhorse001.github.io/LearningApacheSpark/index.html)  
  -  _Website Tutorial / PDF 파일 제공_

## Advanced

[Optimizing Conversion between Spark and Pandas DataFrames using Apache PyArrow](https://blog.clairvoyantsoft.com/optimizing-conversion-between-spark-and-pandas-dataframes-using-apache-pyarrow-9d439cbf2010)  
  -  _Apache Arrow를 통해 JVM과 non-JVM 환경에서 데이터 교환을 효율적으로 하는 방법 설명  
  -  Spark는 default로 Pickle 포맷을 사용하지만 비효율적임_

[클러스터 리소스 최적화를 위한 Spark 아키텍처 소개](https://www.samsungsds.com/global/ko/support/insights/Spark-Cluster-job-server.html) - by Samsung SDS  
  -  _Spark Job Server, Fair Scheduler, Dynamic Resource Allocation_

🎞 [Amazon S3 Best Practice and Tuning for Hadoop/Spark in the Cloud](https://www.slideshare.net/ssuserca76a5/amazon-s3-best-practice-and-tuning-for-hadoopspark-in-the-cloud) - by AWS  
  -  _Spark에서 S3를 데이터 저장소로 활용하는 방법_

## ETC

[Benchmarking Apache Spark on a Single Node Machine](https://databricks.com/blog/2018/05/03/benchmarking-apache-spark-on-a-single-node-machine.html) - by Databricks  
  -  _Single Node로도 데이터 처리\(대용량\)가 pandas보다  뛰어나다는 설명_

[Spark로 알아보는 빅데이터 처리 SlideShare](https://www.slideshare.net/JoenggyuLenKim/spark-152302106?fbclid=IwAR0FWY83VgVU2rpJKB1BswmAbjL_Z1tXqjoJIbKIdQ9A2FA-p6BN7w5xQec) - by 다우기술

